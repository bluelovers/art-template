{"version":3,"sources":["../../src/compile/es-tokenizer.js"],"names":["isKeyword","require","jsTokens","default","matchToToken","esTokenizer","tokens","code","match","map","lastIndex","exec","value","token","type","module","exports"],"mappings":";;AAAA,IAAMA,YAAYC,QAAQ,eAAR,CAAlB;AACA,IAAMC,WAAWD,QAAQ,WAAR,EAAqBE,OAAtC;AACA,IAAMC,eAAeH,QAAQ,WAAR,EAAqBG,YAA1C;;AAEA;;;;;AAKA,IAAMC,cAAc,SAAdA,WAAc,OAAQ;AACxB,QAAMC,SAASC,KACVC,KADU,CACJN,QADI,EAEVO,GAFU,CAEN,iBAAS;AACVP,iBAASQ,SAAT,GAAqB,CAArB;AACA,eAAON,aAAaF,SAASS,IAAT,CAAcC,KAAd,CAAb,CAAP;AACH,KALU,EAMVH,GANU,CAMN,iBAAS;AACV,YAAII,MAAMC,IAAN,KAAe,MAAf,IAAyBd,UAAUa,MAAMD,KAAhB,CAA7B,EAAqD;AACjDC,kBAAMC,IAAN,GAAa,SAAb;AACH;AACD,eAAOD,KAAP;AACH,KAXU,CAAf;;AAaA,WAAOP,MAAP;AACH,CAfD;;AAiBAS,OAAOC,OAAP,GAAiBX,WAAjB","file":"es-tokenizer.js","sourcesContent":["const isKeyword = require('is-keyword-js');\nconst jsTokens = require('js-tokens').default;\nconst matchToToken = require('js-tokens').matchToToken;\n\n/**\n * 将逻辑表达式解释为 Tokens\n * @param {string} code\n * @return {Object[]}\n */\nconst esTokenizer = code => {\n    const tokens = code\n        .match(jsTokens)\n        .map(value => {\n            jsTokens.lastIndex = 0;\n            return matchToToken(jsTokens.exec(value));\n        })\n        .map(token => {\n            if (token.type === 'name' && isKeyword(token.value)) {\n                token.type = 'keyword';\n            }\n            return token;\n        });\n\n    return tokens;\n};\n\nmodule.exports = esTokenizer;\n"]}